{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LS_DS_214_solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbbcoach/DS-Unit-2-Linear-Models/blob/master/Copy_of_LS_DS_214_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HOtIeZnzVO_"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgEuUEVQzVPE"
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CctWTxRCzVPF"
      },
      "source": [
        "# Module Project: Logistic Regression\n",
        "\n",
        "Do you like burritos? ðŸŒ¯ You're in luck then, because in this project you'll create a model to predict whether a burrito is `'Great'`.\n",
        "\n",
        "The dataset for this assignment comes from [Scott Cole](https://srcole.github.io/100burritos/), a San Diego-based data scientist and burrito enthusiast. \n",
        "\n",
        "## Directions\n",
        "\n",
        "The tasks for this project are the following:\n",
        "\n",
        "- **Task 1:** Import `csv` file using `wrangle` function.\n",
        "- **Task 2:** Conduct exploratory data analysis (EDA), and modify `wrangle` function .\n",
        "- **Task 3:** Split data into feature matrix `X` and target vector `y`.\n",
        "- **Task 4:** Split feature matrix `X` and target vector `y` into training and test sets.\n",
        "- **Task 5:** Establish the baseline accuracy score for your dataset.\n",
        "- **Task 6:** Build `model_logr` using a pipeline that includes three transfomers and `LogisticRegression` predictor. Train model on `X_train` and `X_test`.\n",
        "- **Task 7:** Calculate the training and test accuracy score for your model.\n",
        "- **Task 8:** Create a horizontal bar chart showing the 10 most influencial features for your  model. \n",
        "- **Task 9:** Demonstrate and explain the differences between `model_lr.predict()` and `model_lr.predict_proba()`.\n",
        "\n",
        "**Note** \n",
        "\n",
        "You should limit yourself to the following libraries:\n",
        "\n",
        "- `category_encoders`\n",
        "- `matplotlib`\n",
        "- `pandas`\n",
        "- `sklearn`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geYnt-6-0Ope",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0676a816-31bb-4599-98fe-291db9dfbe39"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from category_encoders import OneHotEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CtW1Z-vzVPG"
      },
      "source": [
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-Yvar1vzVPG"
      },
      "source": [
        "def wrangle(filepath):\n",
        "    # Import w/ DateTimeIndex\n",
        "    df = pd.read_csv(filepath, parse_dates=['Date'],\n",
        "                     index_col='Date')\n",
        "    \n",
        "    # Drop unrated burritos\n",
        "    df.dropna(subset=['overall'], inplace=True)\n",
        "    \n",
        "    # Derive binary classification target:\n",
        "    # We define a 'Great' burrito as having an\n",
        "    # overall rating of 4 or higher, on a 5 point scale\n",
        "    df['Great'] = (df['overall'] >= 4).astype(int)\n",
        "    \n",
        "    # Drop high cardinality categoricals\n",
        "    df = df.drop(columns=['Notes', 'Location', 'Address', 'URL'])\n",
        "    \n",
        "    # Drop columns to prevent \"leakage\"\n",
        "    df = df.drop(columns=['Rec', 'overall'])\n",
        "\n",
        "    # binary_cols = ['Unreliable', 'NonSD', 'Beef', 'Pico', 'Guac', 'Cheese', 'Fries',\n",
        "    #             'Sour cream', 'Pork', 'Chicken', 'Shrimp', 'Fish', 'Rice', 'Beans',\n",
        "    #               'Lettuce', 'Tomato', 'Bell peper', 'Carrots', 'Cabbage', 'Sauce',\n",
        "    #               'Salsa.1', 'Cilantro', 'Onion', 'Taquito', 'Pineapple', 'Ham',\n",
        "    #               'Chile relleno', 'Nopales', 'Lobster', 'Queso', 'Egg', 'Mushroom',\n",
        "    #               'Bacon', 'Sushi', 'Avocado', 'Corn', 'Zucchini', 'Chips']\n",
        "\n",
        "    #convert values to 1's and 0's\n",
        "    df.fillna(0, inplace=True)\n",
        "    df.replace({'x': 1}, inplace=True)\n",
        "    df.replace({'X': 1}, inplace=True)\n",
        "\n",
        "    # df[binary_cols].applymap(lambda x: 1 if type(x)==str else 0).head(10)\n",
        "    #also have to define which columns are in 'binary_cols.\n",
        "    \n",
        "    return df\n",
        "\n",
        "filepath = DATA_PATH + 'burritos/burritos.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W1EV2bYzVPH"
      },
      "source": [
        "**Task 1:** Use the above `wrangle` function to import the `burritos.csv` file into a DataFrame named `df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7TZpo6-zVPH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "deabe6e8-a41f-4a60-8bc8-4887eea1cda2"
      },
      "source": [
        "\n",
        "df = wrangle(filepath)\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Burrito</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Chips</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Reviewer</th>\n",
              "      <th>Unreliable</th>\n",
              "      <th>NonSD</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Chicken</th>\n",
              "      <th>Shrimp</th>\n",
              "      <th>Fish</th>\n",
              "      <th>Rice</th>\n",
              "      <th>Beans</th>\n",
              "      <th>Lettuce</th>\n",
              "      <th>Tomato</th>\n",
              "      <th>Bell peper</th>\n",
              "      <th>Carrots</th>\n",
              "      <th>Cabbage</th>\n",
              "      <th>Sauce</th>\n",
              "      <th>Salsa.1</th>\n",
              "      <th>Cilantro</th>\n",
              "      <th>Onion</th>\n",
              "      <th>Taquito</th>\n",
              "      <th>Pineapple</th>\n",
              "      <th>Ham</th>\n",
              "      <th>Chile relleno</th>\n",
              "      <th>Nopales</th>\n",
              "      <th>Lobster</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Egg</th>\n",
              "      <th>Mushroom</th>\n",
              "      <th>Bacon</th>\n",
              "      <th>Sushi</th>\n",
              "      <th>Avocado</th>\n",
              "      <th>Corn</th>\n",
              "      <th>Zucchini</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-18</th>\n",
              "      <td>California</td>\n",
              "      <td>Miramar</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Scott</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>California</td>\n",
              "      <td>San Marcos</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Scott</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>Carnitas</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Emily</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>Carne asada</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Ricardo</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-27</th>\n",
              "      <td>California</td>\n",
              "      <td>Carlsbad</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Scott</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Burrito Neighborhood  Yelp  ...  Corn Zucchini  Great\n",
              "Date                                        ...                      \n",
              "2016-01-18  California       Miramar   3.5  ...     0        0      0\n",
              "2016-01-24  California    San Marcos   3.5  ...     0        0      0\n",
              "2016-01-24     Carnitas            0   0.0  ...     0        0      0\n",
              "2016-01-24  Carne asada            0   0.0  ...     0        0      0\n",
              "2016-01-27   California     Carlsbad   4.0  ...     0        0      1\n",
              "\n",
              "[5 rows x 60 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZQh6y6EzVPH"
      },
      "source": [
        "During your exploratory data analysis, note that there are several columns whose data type is `object` but that seem to be a binary encoding. For example, `df['Beef'].head()` returns:\n",
        "\n",
        "```\n",
        "0      x\n",
        "1      x\n",
        "2    NaN\n",
        "3      x\n",
        "4      x\n",
        "Name: Beef, dtype: object\n",
        "```\n",
        "\n",
        "**Task 2:** Change the `wrangle` function so that these columns are properly encoded as `0` and `1`s. Be sure your code handles upper- and lowercase `X`s, and `NaN`s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Habfl8KzVPH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ecf903-8e9a-4c47-eefe-784a50b6c4ec"
      },
      "source": [
        "# Conduct your exploratory data analysis here\n",
        "# And modify the `wrangle` function above.\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 421 entries, 2016-01-18 to 2019-08-27\n",
            "Data columns (total 60 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   Burrito         421 non-null    object \n",
            " 1   Neighborhood    421 non-null    object \n",
            " 2   Yelp            421 non-null    float64\n",
            " 3   Google          421 non-null    float64\n",
            " 4   Chips           421 non-null    object \n",
            " 5   Cost            421 non-null    float64\n",
            " 6   Hunger          421 non-null    float64\n",
            " 7   Mass (g)        421 non-null    float64\n",
            " 8   Density (g/mL)  421 non-null    float64\n",
            " 9   Length          421 non-null    float64\n",
            " 10  Circum          421 non-null    float64\n",
            " 11  Volume          421 non-null    float64\n",
            " 12  Tortilla        421 non-null    float64\n",
            " 13  Temp            421 non-null    float64\n",
            " 14  Meat            421 non-null    float64\n",
            " 15  Fillings        421 non-null    float64\n",
            " 16  Meat:filling    421 non-null    float64\n",
            " 17  Uniformity      421 non-null    float64\n",
            " 18  Salsa           421 non-null    float64\n",
            " 19  Synergy         421 non-null    float64\n",
            " 20  Wrap            421 non-null    float64\n",
            " 21  Reviewer        421 non-null    object \n",
            " 22  Unreliable      421 non-null    int64  \n",
            " 23  NonSD           421 non-null    int64  \n",
            " 24  Beef            421 non-null    int64  \n",
            " 25  Pico            421 non-null    int64  \n",
            " 26  Guac            421 non-null    int64  \n",
            " 27  Cheese          421 non-null    int64  \n",
            " 28  Fries           421 non-null    int64  \n",
            " 29  Sour cream      421 non-null    int64  \n",
            " 30  Pork            421 non-null    int64  \n",
            " 31  Chicken         421 non-null    int64  \n",
            " 32  Shrimp          421 non-null    int64  \n",
            " 33  Fish            421 non-null    int64  \n",
            " 34  Rice            421 non-null    int64  \n",
            " 35  Beans           421 non-null    int64  \n",
            " 36  Lettuce         421 non-null    int64  \n",
            " 37  Tomato          421 non-null    int64  \n",
            " 38  Bell peper      421 non-null    int64  \n",
            " 39  Carrots         421 non-null    int64  \n",
            " 40  Cabbage         421 non-null    int64  \n",
            " 41  Sauce           421 non-null    int64  \n",
            " 42  Salsa.1         421 non-null    int64  \n",
            " 43  Cilantro        421 non-null    int64  \n",
            " 44  Onion           421 non-null    int64  \n",
            " 45  Taquito         421 non-null    int64  \n",
            " 46  Pineapple       421 non-null    int64  \n",
            " 47  Ham             421 non-null    int64  \n",
            " 48  Chile relleno   421 non-null    int64  \n",
            " 49  Nopales         421 non-null    int64  \n",
            " 50  Lobster         421 non-null    int64  \n",
            " 51  Queso           421 non-null    float64\n",
            " 52  Egg             421 non-null    int64  \n",
            " 53  Mushroom        421 non-null    int64  \n",
            " 54  Bacon           421 non-null    int64  \n",
            " 55  Sushi           421 non-null    int64  \n",
            " 56  Avocado         421 non-null    int64  \n",
            " 57  Corn            421 non-null    int64  \n",
            " 58  Zucchini        421 non-null    int64  \n",
            " 59  Great           421 non-null    int64  \n",
            "dtypes: float64(19), int64(37), object(4)\n",
            "memory usage: 200.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXmlxDWVzVPI"
      },
      "source": [
        "If you explore the `'Burrito'` column of `df`, you'll notice that it's a high-cardinality categorical feature. You'll also notice that there's a lot of overlap between the categories. \n",
        "\n",
        "**Stretch Goal:** Change the `wrangle` function above so that it engineers four new features: `'california'`, `'asada'`, `'surf'`, and `'carnitas'`. Each row should have a `1` or `0` based on the text information in the `'Burrito'` column. For example, here's how the first 5 rows of the dataset would look.\n",
        "\n",
        "| **Burrito** | **california** | **asada** | **surf** | **carnitas** |\n",
        "| :---------- | :------------: | :-------: | :------: | :----------: |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "|  Carnitas   |       0        |     0     |    0     |      1       |\n",
        "| Carne asada |       0        |     1     |    0     |      0       |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "\n",
        "**Note:** Be sure to also drop the `'Burrito'` once you've engineered your new features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBzW-uUuzVPI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "3b8ba6ba-45d1-4bbe-9051-02c305087161"
      },
      "source": [
        "# Conduct your exploratory data analysis here\n",
        "# And modify the `wrangle` function above.\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Burrito</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Chips</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Reviewer</th>\n",
              "      <th>Unreliable</th>\n",
              "      <th>NonSD</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Chicken</th>\n",
              "      <th>Shrimp</th>\n",
              "      <th>Fish</th>\n",
              "      <th>Rice</th>\n",
              "      <th>Beans</th>\n",
              "      <th>Lettuce</th>\n",
              "      <th>Tomato</th>\n",
              "      <th>Bell peper</th>\n",
              "      <th>Carrots</th>\n",
              "      <th>Cabbage</th>\n",
              "      <th>Sauce</th>\n",
              "      <th>Salsa.1</th>\n",
              "      <th>Cilantro</th>\n",
              "      <th>Onion</th>\n",
              "      <th>Taquito</th>\n",
              "      <th>Pineapple</th>\n",
              "      <th>Ham</th>\n",
              "      <th>Chile relleno</th>\n",
              "      <th>Nopales</th>\n",
              "      <th>Lobster</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Egg</th>\n",
              "      <th>Mushroom</th>\n",
              "      <th>Bacon</th>\n",
              "      <th>Sushi</th>\n",
              "      <th>Avocado</th>\n",
              "      <th>Corn</th>\n",
              "      <th>Zucchini</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-18</th>\n",
              "      <td>California</td>\n",
              "      <td>Miramar</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Scott</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>California</td>\n",
              "      <td>San Marcos</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Scott</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>Carnitas</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Emily</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>Carne asada</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Ricardo</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-27</th>\n",
              "      <td>California</td>\n",
              "      <td>Carlsbad</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Scott</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Burrito Neighborhood  Yelp  ...  Corn Zucchini  Great\n",
              "Date                                        ...                      \n",
              "2016-01-18  California       Miramar   3.5  ...     0        0      0\n",
              "2016-01-24  California    San Marcos   3.5  ...     0        0      0\n",
              "2016-01-24     Carnitas            0   0.0  ...     0        0      0\n",
              "2016-01-24  Carne asada            0   0.0  ...     0        0      0\n",
              "2016-01-27   California     Carlsbad   4.0  ...     0        0      1\n",
              "\n",
              "[5 rows x 60 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gajhoVWCzVPI"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 3:** Split your dataset into the feature matrix `X` and the target vector `y`. You want to predict `'Great'`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPo8etcOzVPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fafde26-db6a-4073-d850-29a02a2425f2"
      },
      "source": [
        "target = 'Great'\n",
        "\n",
        "\n",
        "X = df.drop(columns= target)\n",
        "y = df[target]\n",
        "\n",
        "y.shape, X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((421,), (421, 59))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_iUtULEzVPJ"
      },
      "source": [
        "**Task 4:** Split `X` and `y` into a training set (`X_train`, `y_train`) and a test set (`X_test`, `y_test`).\n",
        "\n",
        "- Your training set should include data from 2016 through 2017. \n",
        "- Your test set should include data from 2018 and later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TDBHuqYzVPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6421d14b-ea47-41bc-b53d-7e5088c5faea"
      },
      "source": [
        "cutoff = '2018'\n",
        "mask = X.index < cutoff\n",
        "\n",
        "X_train, y_train = X.loc[mask], y.loc[mask]\n",
        "X_test, y_test = X.loc[~mask], y.loc[~mask]\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((383, 59), (383,), (38, 59), (38,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWZGJEt9zVPK"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "**Task 5:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPPDLyotzVPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2180e50-2f3d-48a9-8895-5e813482d582"
      },
      "source": [
        "\n",
        "y_train.value_counts(normalize=True) * 100\n",
        "majority_class = y_train.mode()[0]\n",
        "y_pred = [majority_class] * len(y_train)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "baseline_acc = accuracy_score(y_train, y_pred)\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print('Baseline Accuracy Score:', baseline_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    0.582245\n",
            "1    0.417755\n",
            "Name: Great, dtype: float64\n",
            "Baseline Accuracy Score: 0.5822454308093995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_5KFt3pzVPL"
      },
      "source": [
        "# IV. Build Model\n",
        "\n",
        "**Task 6:** Build a `Pipeline` named `model_logr`, and fit it to your training data. Your pipeline should include:\n",
        "\n",
        "- a `OneHotEncoder` transformer for categorical features, \n",
        "- a `SimpleImputer` transformer to deal with missing values, \n",
        "- a [`StandarScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) transfomer (which often improves performance in a logistic regression model), and \n",
        "- a `LogisticRegression` predictor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih5U_RdBzVPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e4b5a49-7983-49e0-f776-2a2cd33fceb7"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model_logr = make_pipeline(\n",
        "   OneHotEncoder(use_cat_names=True),\n",
        "   SimpleImputer(),\n",
        "   StandardScaler(), \n",
        "   LogisticRegression()\n",
        ")\n",
        "\n",
        "model_logr.fit(X_train, y_train)\n",
        "#print('Accuracy from pipeling', model_logr.score(X_remain, y_train))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('onehotencoder',\n",
              "                 OneHotEncoder(cols=['Burrito', 'Neighborhood', 'Chips',\n",
              "                                     'Reviewer'],\n",
              "                               drop_invariant=False, handle_missing='value',\n",
              "                               handle_unknown='value', return_df=True,\n",
              "                               use_cat_names=True, verbose=0)),\n",
              "                ('simpleimputer',\n",
              "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
              "                               missing_values=nan, strategy='mean',\n",
              "                               verbose=0)),\n",
              "                ('standardscaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('logisticregression',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_rEGXwBzVPM"
      },
      "source": [
        "# IV. Check Metrics\n",
        "\n",
        "**Task 7:** Calculate the training and test accuracy score for `model_lr`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXY28R2yzVPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78555c6f-3850-4aec-ae85-3cf751d27c9f"
      },
      "source": [
        "\n",
        "training_acc = model_logr.score(X_train, y_train)\n",
        "test_acc = model_logr.score(X_test, y_test)\n",
        "\n",
        "print('Training MAE:', training_acc)\n",
        "print('Test MAE:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training MAE: 0.9895561357702349\n",
            "Test MAE: 0.7631578947368421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIiJFeejzVPN"
      },
      "source": [
        "# V. Communicate Results\n",
        "\n",
        "**Task 8:** Create a horizontal barchart that plots the 10 most important coefficients for `model_lr`, sorted by absolute value.\n",
        "\n",
        "**Note:** Since you created your model using a `Pipeline`, you'll need to use the [`named_steps`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) attribute to access the coefficients in your `LogisticRegression` predictor. Be sure to look at the shape of the coefficients array before you combine it with the feature names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeaVjKs0zVPN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "553da0f7-fafd-41e3-ac04-2a9f5b5e13c3"
      },
      "source": [
        "# Create your horizontal barchart here.\n",
        "coefficients = model_logr.named_steps['logisticregression'].coef_[0]\n",
        "features = model_logr.named_steps['onehotencoder'].get_feature_names()\n",
        "feat_imp = pd.Series(coefficients, index=features).sort_values(key=abs)\n",
        "feat_imp.tail(10).plot(kind='barh');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqi2hn0RzVPN"
      },
      "source": [
        "There is more than one way to generate predictions with `model_lr`. For instance, you can use [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression) or [`predict_proba`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression#sklearn.linear_model.LogisticRegression.predict_proba).\n",
        "\n",
        "**Task 9:** Generate predictions for `X_test` using both `predict` and `predict_proba`. Then below, write a summary of the differences in the output for these two methods. You should answer the following questions:\n",
        "\n",
        "- What data type do `predict` and `predict_proba` output?\n",
        "- What are the shapes of their different output?\n",
        "- What numerical values are in the output?\n",
        "- What do those numerical values represent?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckZEorX4zVPN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1010a90-5f3a-4cad-8b8b-16a50ab60317"
      },
      "source": [
        "# Write code here to explore the differences between `predict` and `predict_proba`.\n",
        "np.round(model_logr.predict_proba(X_test)), np.round(model_logr.predict(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 1.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [0., 1.]]),\n",
              " array([1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
              "        0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCkvdphCzVPO"
      },
      "source": [
        "**Give your written answer here:**\n",
        "\n",
        "```Predict gives the prediction for which class might occur based on features - in this case whether a burrito was great or not.  Predict_proba gives the probably of a feature being 1 or 0\n",
        "\n",
        "Predict gives the prediction for which class might occur based on features - in this case whether a burrito was great or not.  Predict_proba gives the probably of a feature being 1 or 0\n",
        "\n",
        "```"
      ]
    }
  ]
}